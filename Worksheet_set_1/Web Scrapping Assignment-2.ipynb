{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad8cd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ara resources private limited</td>\n",
       "      <td>4 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+3</td>\n",
       "      <td>diraa hr services hiring for mncs</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vacancy For Data Analyst</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Management</td>\n",
       "      <td>Bangalore\\n+18</td>\n",
       "      <td>future solution centre</td>\n",
       "      <td>15 to &gt;25 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Modeler data</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Modeller</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Modeler Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Modeler</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Job Title    Job Location  \\\n",
       "0         Lead Data Analyst       Bangalore   \n",
       "1              Data Analyst   Bangalore\\n+3   \n",
       "2  Vacancy For Data Analyst  Bangalore\\n+14   \n",
       "3     Clinical Data Analyst   Bangalore\\n+6   \n",
       "4           Data Management  Bangalore\\n+18   \n",
       "5         Data Modeler data       Bangalore   \n",
       "6             Data Modeller       Bangalore   \n",
       "7    Data Modeler Bangalore       Bangalore   \n",
       "8              Data Modeler       Bangalore   \n",
       "9     Clinical Data Analyst   Bangalore\\n+4   \n",
       "\n",
       "                             Company Name Experience Required  \n",
       "0           ara resources private limited          4 to 9 Yrs  \n",
       "1       diraa hr services hiring for mncs           0 to 1 Yr  \n",
       "2                yogita staffing solution          0 to 3 Yrs  \n",
       "3                           techno endura           0 to 1 Yr  \n",
       "4                  future solution centre       15 to >25 Yrs  \n",
       "5  boyen haddin consulting and technol...          3 to 6 Yrs  \n",
       "6  boyen haddin consulting and technol...          3 to 6 Yrs  \n",
       "7  boyen haddin consulting and technol...          3 to 6 Yrs  \n",
       "8  boyen haddin consulting and technol...          3 to 6 Yrs  \n",
       "9                         quiscon biotech          0 to 2 Yrs  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.'''\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver =webdriver.Chrome()  # Initializing web driver\n",
    "\n",
    "driver.get('https://www.shine.com/')  # Opening shine.com\n",
    "driver.maximize_window()\n",
    "time.sleep(30)\n",
    "\n",
    "\n",
    "# Filling criteria to search job \n",
    "designation =driver.find_element(By.XPATH, '/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input')\n",
    "designation.send_keys('Data Analyst')\n",
    "time.sleep(20)\n",
    "\n",
    "location =driver.find_element(By.XPATH, '/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys('Bangalore')\n",
    "time.sleep(20)\n",
    "\n",
    "search =driver.find_element(By.CLASS_NAME, 'searchForm_btnWrap_advance__VYBHN')\n",
    "search.click()\n",
    "\n",
    "#Creating empty list\n",
    "job_title =[]\n",
    "job_location =[]\n",
    "company_name =[]\n",
    "experience_required =[]\n",
    "\n",
    "# Scrapping job title from the given page\n",
    "title_tags =driver.find_elements(By.XPATH, '//h2[@itemprop=\"name\"]/a')\n",
    "for i in title_tags[0:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "# Scrapping job location from the given page\n",
    "location_tag =driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "# Scrapping company name from the given page\n",
    "company_tag =driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "# Scrapping experience required from the given page\n",
    "exp_tag =driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in exp_tag[0:10]:\n",
    "    experience_required.append(i.text)\n",
    "    \n",
    "# Creating DataFrame with all the searched data\n",
    "df =pd.DataFrame({'Job Title': job_title, 'Job Location': job_location, 'Company Name': company_name, \n",
    "                  'Experience Required': experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21d7951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML Data Scientist</td>\n",
       "      <td>Bangalore\\n+3</td>\n",
       "      <td>gujarat facility services hiring fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>acme services private limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ltimindtree limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist/ Principal Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>fractal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vacancy For Data Scientist Fresher and Experience</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>neostats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>aereo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title        Location  \\\n",
       "0                                  ML Data Scientist   Bangalore\\n+3   \n",
       "1                      Data Scientist Urgent Vacancy  Bangalore\\n+15   \n",
       "2                         Data Scientist Recruitment  Bangalore\\n+15   \n",
       "3                         Data Scientist Recruitment  Bangalore\\n+15   \n",
       "4                                     Data Scientist   Bangalore\\n+4   \n",
       "5                                     Data Scientist       Bangalore   \n",
       "6      Lead Data Scientist/ Principal Data Scientist   Bangalore\\n+1   \n",
       "7  Vacancy For Data Scientist Fresher and Experience  Bangalore\\n+14   \n",
       "8                              Senior Data Scientist   Bangalore\\n+1   \n",
       "9                                Lead Data Scientist   Bangalore\\n+1   \n",
       "\n",
       "                             Company Name  \n",
       "0  gujarat facility services hiring fo...  \n",
       "1                      renuka interprises  \n",
       "2                      renuka interprises  \n",
       "3                      renuka interprises  \n",
       "4           acme services private limited  \n",
       "5                     ltimindtree limited  \n",
       "6                                 fractal  \n",
       "7                yogita staffing solution  \n",
       "8                                neostats  \n",
       "9                                   aereo  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "'''\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver =webdriver.Chrome()   # Initializing web driver\n",
    "\n",
    "driver.get('https://www.shine.com/')  # Opening shine.com\n",
    "\n",
    "# Filling criteria to search job \n",
    "designation =driver.find_element(By.XPATH, '/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input')\n",
    "designation.send_keys('Data Scientist')\n",
    "\n",
    "location =driver.find_element(By.XPATH, '/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys('Bangalore')\n",
    "\n",
    "search =driver.find_element(By.CLASS_NAME, 'searchForm_btnWrap_advance__VYBHN')\n",
    "search.click()\n",
    "\n",
    "# Creating empty list\n",
    "job_title =[]\n",
    "job_location =[]\n",
    "company_name =[]\n",
    "\n",
    "# Scrapping job title from the given page\n",
    "job_tag =driver.find_elements(By.XPATH, '//h2[@itemprop=\"name\"]')\n",
    "for i in job_tag[0:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "# Scrapping job location from the given page\n",
    "location_tag =driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "# Scrapping company name from the given page\n",
    "company_tag =driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "# Creating Dataframe\n",
    "df =pd.DataFrame({'Job Title': job_title, 'Location': job_location, 'Company Name': company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69945042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Australia\\n+2</td>\n",
       "      <td>advance immigrations</td>\n",
       "      <td>8 to 13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Virgin Islands (Uk)\\n+3</td>\n",
       "      <td>skywalk visa immigration services l...</td>\n",
       "      <td>2 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML Data Scientist</td>\n",
       "      <td>Bangalore\\n+3</td>\n",
       "      <td>gujarat facility services hiring fo...</td>\n",
       "      <td>5 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist | Senior Data Scientist Chennai</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>talent leads hr solutions pvt ltd</td>\n",
       "      <td>8 to 13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Canada\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Canada\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Canada\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram\\n+1</td>\n",
       "      <td>right advisors private limited</td>\n",
       "      <td>2 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist/Data Analyst-17740</td>\n",
       "      <td>All India</td>\n",
       "      <td>gemraj technologies ltd</td>\n",
       "      <td>3 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist - Claims Analysis</td>\n",
       "      <td>Other Karnataka</td>\n",
       "      <td>molecular connections</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Job Title             Job Location  \\\n",
       "0                                  Data Scientist            Australia\\n+2   \n",
       "1                                  Data Scientist  Virgin Islands (Uk)\\n+3   \n",
       "2                               ML Data Scientist            Bangalore\\n+3   \n",
       "3  Data Scientist | Senior Data Scientist Chennai                  Chennai   \n",
       "4                   Data Scientist Urgent Vacancy              Canada\\n+15   \n",
       "5                   Data Scientist Urgent Vacancy              Canada\\n+15   \n",
       "6                   Data Scientist Urgent Vacancy              Canada\\n+15   \n",
       "7                                  Data Scientist             Gurugram\\n+1   \n",
       "8               Data Scientist/Data Analyst-17740                All India   \n",
       "9         Senior Data Scientist - Claims Analysis          Other Karnataka   \n",
       "\n",
       "                             Company Name Experience Required  \n",
       "0                    advance immigrations         8 to 13 Yrs  \n",
       "1  skywalk visa immigration services l...          2 to 7 Yrs  \n",
       "2  gujarat facility services hiring fo...          5 to 8 Yrs  \n",
       "3       talent leads hr solutions pvt ltd         8 to 13 Yrs  \n",
       "4                      renuka interprises          0 to 4 Yrs  \n",
       "5                      renuka interprises          0 to 4 Yrs  \n",
       "6                      renuka interprises          0 to 4 Yrs  \n",
       "7          right advisors private limited          2 to 7 Yrs  \n",
       "8                 gemraj technologies ltd          3 to 7 Yrs  \n",
       "9                   molecular connections          2 to 5 Yrs  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q3: In this question you have to scrape data using the filters available on the webpage\n",
    "You have to use the location and salary filter.\n",
    "'''\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver =webdriver.Chrome() # Initializing web driver\n",
    "\n",
    "driver.get('https://www.shine.com/')  # Opening shine.com\n",
    "\n",
    "#Filling criteria to search job\n",
    "designation =driver.find_element(By.XPATH, '/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input')\n",
    "designation.send_keys('Data Scientist')\n",
    "\n",
    "location =driver.find_element(By.XPATH, '/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys('Delhi/NCR')\n",
    "\n",
    "salary =driver.find_element(By.XPATH, '/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul[2]/li[1]/div/input[1]')\n",
    "salary.send_keys('3- 6 Lakh')\n",
    "\n",
    "search =driver.find_element(By.CLASS_NAME, 'searchForm_btnWrap_advance__VYBHN')\n",
    "search.click()\n",
    "\n",
    "# Creating empty list\n",
    "job_title =[]\n",
    "job_location =[]\n",
    "company_name =[]\n",
    "experience_required =[]\n",
    "\n",
    "# Scrapping job title from the given page\n",
    "title_tag =driver.find_elements(By.XPATH, '//h2[@itemprop=\"name\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "# Scrapping job location from the given page\n",
    "location_tag =driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "# Scrapping Company Name from the given page\n",
    "company_tag =driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "# Scrapping experience required from the given page\n",
    "experience_tag =driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tag[0:10]:\n",
    "    experience_required.append(i.text)\n",
    "    \n",
    "# Creating DataFrame\n",
    "df =pd.DataFrame({'Job Title': job_title, 'Job Location': job_location,\n",
    "                  'Company Name': company_name, 'Experience Required': experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5da3b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Eyewearlabs</td>\n",
       "      <td>UV Protection, Gradient Butterfly Sunglasses (52)</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (58)</td>\n",
       "      <td>₹539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Niavaa</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Mirrored Round Sunglasses (53)</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>₹497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Eyewearlabs</td>\n",
       "      <td>Polarized, UV Protection, Mirrored Wayfarer, R...</td>\n",
       "      <td>₹2,199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SPORT COLLECTION</td>\n",
       "      <td>UV Protection, Gradient Wayfarer Sunglasses (59)</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Over-sized Sunglasses (65)</td>\n",
       "      <td>₹169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand Name                                Product Description  \\\n",
       "90         ROYAL SON  by Lenskart Polarized, UV Protection Wayfarer ...   \n",
       "91       Eyewearlabs  UV Protection, Gradient Butterfly Sunglasses (52)   \n",
       "92          Fastrack      UV Protection, Gradient Round Sunglasses (58)   \n",
       "93            Niavaa  UV Protection Cat-eye, Retro Square, Oval, Rou...   \n",
       "94     VINCENT CHASE                     Mirrored Round Sunglasses (53)   \n",
       "95           ROADWAY         UV Protection Round Sunglasses (Free Size)   \n",
       "96            AISLIN             UV Protection Wayfarer Sunglasses (53)   \n",
       "97       Eyewearlabs  Polarized, UV Protection, Mirrored Wayfarer, R...   \n",
       "98  SPORT COLLECTION   UV Protection, Gradient Wayfarer Sunglasses (59)   \n",
       "99         Elligator           UV Protection Over-sized Sunglasses (65)   \n",
       "\n",
       "     Price  \n",
       "90    ₹418  \n",
       "91  ₹1,999  \n",
       "92    ₹539  \n",
       "93    ₹247  \n",
       "94    ₹499  \n",
       "95    ₹129  \n",
       "96    ₹497  \n",
       "97  ₹2,199  \n",
       "98    ₹399  \n",
       "99    ₹169  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "6. Brand\n",
    "7. Product Description\n",
    "8. Price\n",
    "'''\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver =webdriver.Chrome()  # Initializing web driver\n",
    "\n",
    "driver.get('https://www.flipkart.com/')  # Opening flipkart.com\n",
    "\n",
    "# Filling criteria to search Sunglasses\n",
    "designation =driver.find_element(By.CLASS_NAME, 'Pke_EE')\n",
    "designation.send_keys('Sunglasses')\n",
    "\n",
    "search =driver.find_element(By.XPATH, '/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button')\n",
    "search.click()\n",
    "\n",
    "#Creating empty list to store data\n",
    "brand =[]\n",
    "productdesc =[]\n",
    "price =[]\n",
    "\n",
    "# Scrapping Sunglasses Brand from the given page\n",
    "start =0\n",
    "end =3\n",
    "\n",
    "for page in range(start,end):\n",
    "    brand_tag =driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tag:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "        if len(brand)==100:\n",
    "            break\n",
    "        \n",
    "    next_button =driver.find_element(By.CLASS_NAME, '_1LKTO3')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "# Scrapping Sunglasses description from the given page\n",
    "start =0\n",
    "end =3\n",
    "\n",
    "for page in range(start,end):\n",
    "    product_tag =driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_tag:\n",
    "        productdesc.append(i.text)\n",
    "        \n",
    "        if len(productdesc) ==100:\n",
    "            break\n",
    "            \n",
    "    next_button =driver.find_element(By.CLASS_NAME, '_1LKTO3')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "# Scrapping Sunglasses price from the given page\n",
    "start =0\n",
    "end =3\n",
    "\n",
    "for page in range(start, end):\n",
    "    price_tag=driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_tag:\n",
    "        price.append(i.text)\n",
    "        \n",
    "        if len(price) ==100:\n",
    "            break\n",
    "            \n",
    "    next_button =driver.find_element(By.CLASS_NAME, '_1LKTO3')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "# Creating dataframe to display data\n",
    "df =pd.DataFrame({'Brand Name': brand, 'Product Description': productdesc, 'Price':price})\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ffcfdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>It’s really awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>iPhone 11 is a good phone. Not a very big diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Excellent Phone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>very good camera quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>It’s very good battery life and display and vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money 🖤🖤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Go for iPhone 11 , if confused between iPhone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Good product 👌I love iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating             Review  \\\n",
       "90      5          Must buy!   \n",
       "91      5            Awesome   \n",
       "92      5          Brilliant   \n",
       "93      5          Brilliant   \n",
       "94      5          Excellent   \n",
       "95      5          Fabulous!   \n",
       "96      5  Terrific purchase   \n",
       "97      5          Must buy!   \n",
       "98      5             Super!   \n",
       "99      5     Simply awesome   \n",
       "\n",
       "                                          Full Review  \n",
       "90                                It’s really awesome  \n",
       "91  iPhone 11 is a good phone. Not a very big diff...  \n",
       "92                                   Excellent Phone.  \n",
       "93                           very good camera quality  \n",
       "94                                                NYC  \n",
       "95  It’s very good battery life and display and vi...  \n",
       "96                                 Value for money 🖤🖤  \n",
       "97  Go for iPhone 11 , if confused between iPhone ...  \n",
       "98                        Good product 👌I love iPhone  \n",
       "99  Really satisfied with the Product I received.....  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product- reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market place=FLIPKART\n",
    "'''\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver =webdriver.Chrome()  # Initializing web driver\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-128-gb/product-reviews/itm8244e8d955aba?pid=MOBFWQ6BKRYBP5X8&lid=LSTMOBFWQ6BKRYBP5X8X0KYUG&marketplace=FLIPKART')\n",
    "driver.maximize_window()\n",
    "\n",
    "# Creating empty list\n",
    "rating =[]\n",
    "review =[]\n",
    "fullreview =[]\n",
    "\n",
    "# Scrapping rating from flipkart.com\n",
    "start =0\n",
    "end =10\n",
    "\n",
    "for page in range(start, end):\n",
    "    rating_tag =driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    \n",
    "    for i in rating_tag:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        if len(rating) ==100:\n",
    "            break\n",
    "            \n",
    "    next_button =driver.find_element(By.CLASS_NAME, '_1LKTO3')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "# Scrapping review from flipkart.com\n",
    "start =0\n",
    "end =10\n",
    "\n",
    "for page in range(start, end):\n",
    "    review_tag =driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "    \n",
    "    for i in review_tag:\n",
    "        review.append(i.text)\n",
    "        \n",
    "        if len(review) ==100:\n",
    "            break\n",
    "            \n",
    "    next_button =driver.find_element(By.CLASS_NAME, '_1LKTO3')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "# Scrapping full review from flipkart.com\n",
    "start =0\n",
    "end =10\n",
    "\n",
    "for page in range(start, end):\n",
    "    fullreview_tag =driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "    \n",
    "    for i in fullreview_tag:\n",
    "        fullreview.append(i.text)\n",
    "        \n",
    "        if len(fullreview) ==100:\n",
    "            break\n",
    "            \n",
    "    next_button =driver.find_element(By.CLASS_NAME, '_1LKTO3')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "# Creating Dataframe\n",
    "df =pd.DataFrame({'Rating': rating, 'Review': review, 'Full Review': fullreview})\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af65611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ATOM</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹1,339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>TR</td>\n",
       "      <td>Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...</td>\n",
       "      <td>₹305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ATOM</td>\n",
       "      <td>CAVE-O Sneakers For Men</td>\n",
       "      <td>₹1,089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Casual Sneaker Shoes For Women | Stylish and C...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Casual Sneaker Shoes for Men | Soft Cushioned ...</td>\n",
       "      <td>₹1,569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>TR</td>\n",
       "      <td>Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...</td>\n",
       "      <td>₹325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>lejano</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Shoe Lab</td>\n",
       "      <td>TRACK - KNOCKHILL Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneaker Casual Shoes for Men | Soft Cushioned ...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand Name                                Product Description   Price\n",
       "90       ATOM                                 Sneakers For Women  ₹1,339\n",
       "91         TR  Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...    ₹305\n",
       "92       ATOM                            CAVE-O Sneakers For Men  ₹1,089\n",
       "93     BRUTON                                 Sneakers For Women    ₹325\n",
       "94       aadi  Casual Sneaker Shoes For Women | Stylish and C...    ₹299\n",
       "95       PUMA  Casual Sneaker Shoes for Men | Soft Cushioned ...  ₹1,569\n",
       "96         TR  Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...    ₹325\n",
       "97     lejano                                   Sneakers For Men    ₹430\n",
       "98   Shoe Lab                 TRACK - KNOCKHILL Sneakers For Men    ₹399\n",
       "99  Deals4you  Sneaker Casual Shoes for Men | Soft Cushioned ...    ₹299"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver =webdriver.Chrome()  # Initializing web driver\n",
    "driver.get('https://www.flipkart.com')  # Opening page flipkart.com\n",
    "driver.maximize_window()\n",
    "\n",
    "# Filling search criteria\n",
    "searchbox =driver.find_element(By.CLASS_NAME, 'Pke_EE')\n",
    "searchbox.send_keys('sneakers')\n",
    "\n",
    "search =driver.find_element(By.CLASS_NAME, '_2iLD__')\n",
    "search.click()\n",
    "\n",
    "# Creating empty list\n",
    "brand =[]\n",
    "productdesc =[]\n",
    "price =[]\n",
    "\n",
    "# Scrapping brand from flipkart.com\n",
    "start =0\n",
    "end =3\n",
    "\n",
    "for page in range(start, end):\n",
    "    brand_tag =driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "    \n",
    "    for i in brand_tag:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "        if len(brand) ==100:\n",
    "            break\n",
    "            \n",
    "    next_button =driver.find_element(By.CLASS_NAME, '_1LKTO3')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n",
    "# Scrapping product description from flipkart.com\n",
    "start =0\n",
    "end =3\n",
    "\n",
    "for page in range(start, end):\n",
    "    productdesc_tag =driver.find_elements(By.XPATH, '//div[@class=\"_2B099V\"]/a[1]')\n",
    "    \n",
    "    for i in productdesc_tag:\n",
    "        productdesc.append(i.text)\n",
    "        \n",
    "        if len(productdesc) ==100:\n",
    "            break\n",
    "            \n",
    "    next_button =driver.find_element(By.CLASS_NAME, '_1LKTO3')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "# Scrapping price from flipkart.com\n",
    "start =0\n",
    "end =3\n",
    "\n",
    "for page in range(start, end):\n",
    "    price_tag =driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    \n",
    "    for i in price_tag:\n",
    "        price.append(i.text)\n",
    "        \n",
    "        if len(price) ==100:\n",
    "            break\n",
    "            \n",
    "    next_button =driver.find_element(By.CLASS_NAME, '_1LKTO3')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "#Creating dataframe\n",
    "df =pd.DataFrame({'Brand Name': brand, 'Product Description': productdesc, 'Price': price})\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3bbc10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Laptop 15, Intel Celeron N4500, 15.6-inch (...</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "      <td>26,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS BR1100 Laptop, 11.6\" (29.46cm) HD Anti-Gl...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>15,697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Chromebook X360 Intel Celeron N4120 14 inch...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>26,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 1 Intel Celeron N4020 14\" ...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>24,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook 15, Intel Celeron N4020, 15.6\" (...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>27,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad 1 Intel Core Celeron N4020 14\" ...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>26,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad 1 Intel Core Celeron N4020 14\" ...</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "      <td>22,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo V15 Intel Celeron N4500 15.6\" (39.62 cm...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>22,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AXL VayuBook Laptop 14.1 Inch FHD IPS Display ...</td>\n",
       "      <td>3.2 out of 5 stars</td>\n",
       "      <td>12,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS BR1100 Notebook 12 (2022), 11.6-inch HD, ...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>14,690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Product Title              Rating  \\\n",
       "0  HP Laptop 15, Intel Celeron N4500, 15.6-inch (...  3.3 out of 5 stars   \n",
       "1  ASUS BR1100 Laptop, 11.6\" (29.46cm) HD Anti-Gl...  4.5 out of 5 stars   \n",
       "2  HP Chromebook X360 Intel Celeron N4120 14 inch...  3.9 out of 5 stars   \n",
       "3  Lenovo IdeaPad Slim 1 Intel Celeron N4020 14\" ...  3.9 out of 5 stars   \n",
       "4  ASUS Vivobook 15, Intel Celeron N4020, 15.6\" (...  3.9 out of 5 stars   \n",
       "5  Lenovo IdeaPad 1 Intel Core Celeron N4020 14\" ...  5.0 out of 5 stars   \n",
       "6  Lenovo IdeaPad 1 Intel Core Celeron N4020 14\" ...  3.7 out of 5 stars   \n",
       "7  Lenovo V15 Intel Celeron N4500 15.6\" (39.62 cm...  3.8 out of 5 stars   \n",
       "8  AXL VayuBook Laptop 14.1 Inch FHD IPS Display ...  3.2 out of 5 stars   \n",
       "9  ASUS BR1100 Notebook 12 (2022), 11.6-inch HD, ...  4.0 out of 5 stars   \n",
       "\n",
       "    Price  \n",
       "0  26,100  \n",
       "1  15,697  \n",
       "2  26,990  \n",
       "3  24,990  \n",
       "4  27,990  \n",
       "5  26,490  \n",
       "6  22,490  \n",
       "7  22,990  \n",
       "8  12,990  \n",
       "9  14,690  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. \n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "'''\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver =webdriver.Chrome()  # Initializing web driver\n",
    "driver.get('https://www.amazon.in/')  # Opening amazon.in\n",
    "driver.maximize_window()\n",
    "\n",
    "#Filling criteria to search\n",
    "searchbox =driver.find_element(By.XPATH, '/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "searchbox.send_keys('Laptop')\n",
    "\n",
    "search =driver.find_element(By.XPATH, '/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search.click()\n",
    "\n",
    "cpu =driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[19]/span/span[9]/li/span/a/span')\n",
    "cpu.click()\n",
    "\n",
    "# Creating empty list\n",
    "title =[]\n",
    "rating =[]\n",
    "price =[]\n",
    "\n",
    "# Scraping product title from amazon\n",
    "title_tag =driver.find_elements(By.XPATH, '//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "\n",
    "for i in title_tag[0:10]:\n",
    "    title.append(i.text)\n",
    "    \n",
    "# Scraping product rating from amazon\n",
    "rating_tag =driver.find_elements(By.XPATH, '//div[@class=\"a-row a-size-small\"]/span[1]')\n",
    "\n",
    "for i in rating_tag[0:10]:\n",
    "    rating.append(i.get_attribute('aria-label'))\n",
    "    \n",
    "# Scraping product rating from amazon\n",
    "price_tag =driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "\n",
    "for i in price_tag[0:10]:\n",
    "    price.append(i.text)\n",
    "    \n",
    "#Creating Dataframe\n",
    "df =pd.DataFrame({'Product Title': title, 'Rating': rating, 'Price': price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7033bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Quote Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Give me six hours to chop down a tree and I wi...</td>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Inspirational, Motivational, Leadership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>We have to be careful in how we use this light...</td>\n",
       "      <td>Melinda Gates</td>\n",
       "      <td>Light, Use, Be Careful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>To solve any problem, here are three questions...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Mistake, Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>You've got to know your limitations. I don't k...</td>\n",
       "      <td>Johnny Cash</td>\n",
       "      <td>Twelve, Way, Found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>I always wonder why birds choose to stay in th...</td>\n",
       "      <td>Harun Yahya</td>\n",
       "      <td>Inspirational, Success, Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>To love means loving the unlovable. To forgive...</td>\n",
       "      <td>Gilbert K. Chesterton</td>\n",
       "      <td>Love, Inspirational, Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Be brave. Take risks. Nothing can substitute e...</td>\n",
       "      <td>Paulo Coelho</td>\n",
       "      <td>Encouraging, Courage, Inspiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>If you really want to do something, you'll fin...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Motivational, Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>It is neither wealth nor splendor; but tranqui...</td>\n",
       "      <td>Thomas Jefferson</td>\n",
       "      <td>Life, Happiness, Work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>A thousand words will not leave so deep an imp...</td>\n",
       "      <td>Henrik Ibsen</td>\n",
       "      <td>Inspirational, Inspiring, Positivity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quotes            Author Name  \\\n",
       "990  Give me six hours to chop down a tree and I wi...        Abraham Lincoln   \n",
       "991  We have to be careful in how we use this light...          Melinda Gates   \n",
       "992  To solve any problem, here are three questions...               Jim Rohn   \n",
       "993  You've got to know your limitations. I don't k...            Johnny Cash   \n",
       "994  I always wonder why birds choose to stay in th...            Harun Yahya   \n",
       "995  To love means loving the unlovable. To forgive...  Gilbert K. Chesterton   \n",
       "996  Be brave. Take risks. Nothing can substitute e...           Paulo Coelho   \n",
       "997  If you really want to do something, you'll fin...               Jim Rohn   \n",
       "998  It is neither wealth nor splendor; but tranqui...       Thomas Jefferson   \n",
       "999  A thousand words will not leave so deep an imp...           Henrik Ibsen   \n",
       "\n",
       "                                  Quote Type  \n",
       "990  Inspirational, Motivational, Leadership  \n",
       "991                   Light, Use, Be Careful  \n",
       "992         Inspirational, Mistake, Learning  \n",
       "993                       Twelve, Way, Found  \n",
       "994           Inspirational, Success, Travel  \n",
       "995             Love, Inspirational, Success  \n",
       "996        Encouraging, Courage, Inspiration  \n",
       "997     Inspirational, Motivational, Success  \n",
       "998                    Life, Happiness, Work  \n",
       "999     Inspirational, Inspiring, Positivity  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver =webdriver.Chrome()  # Initializing web driver\n",
    "driver.get('https://www.azquotes.com/')  # Opening azquotes.com\n",
    "driver.maximize_window()\n",
    "\n",
    "# Click on Top Quotes\n",
    "top_quotes =driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top_quotes.click()\n",
    "\n",
    "# Creating empty list\n",
    "quotes =[]\n",
    "author =[]\n",
    "quote_type =[]\n",
    "\n",
    "# Scraping quotes\n",
    "start =0\n",
    "end =10\n",
    "x =1\n",
    "\n",
    "for page in range(start, end):\n",
    "    quotes_tag =driver.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "    \n",
    "    for i in quotes_tag:\n",
    "        quotes.append(i.text)\n",
    "    \n",
    "    x+=1  # To skip click on next button on last page\n",
    "    if x ==10:\n",
    "        continue\n",
    "    next_button =driver.find_element(By.CLASS_NAME, 'next')\n",
    "    next_button.click()\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "# Scraping author\n",
    "first =driver.find_element(By.CLASS_NAME, 'first')\n",
    "first.click()\n",
    "\n",
    "start =0\n",
    "end =10\n",
    "x =1\n",
    "\n",
    "for page in range(start, end):\n",
    "    author_tag =driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "    \n",
    "    for i in author_tag:\n",
    "        author.append(i.text)\n",
    "    \n",
    "    x+=1  # To skip click on next button on last page\n",
    "    if x ==10:\n",
    "        continue\n",
    "    next_button =driver.find_element(By.CLASS_NAME, 'next')\n",
    "    next_button.click()\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "# Scraping quotes type\n",
    "first =driver.find_element(By.CLASS_NAME, 'first')\n",
    "first.click()\n",
    "\n",
    "start =0\n",
    "end =10\n",
    "x =1\n",
    "\n",
    "for page in range(start, end):\n",
    "    qtype_tag =driver.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "    \n",
    "    for i in qtype_tag:\n",
    "        quote_type.append(i.text)\n",
    "    \n",
    "    x+=1  # To skip click on next button on last page\n",
    "    if x ==10:\n",
    "        continue\n",
    "    next_button =driver.find_element(By.CLASS_NAME, 'next')\n",
    "    next_button.click()\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "# Creating dataframe\n",
    "df =pd.DataFrame({'Quotes': quotes, 'Author Name': author, 'Quote Type': quote_type})\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f82af8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prime Minister Name</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term of Office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 1966</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996</td>\n",
       "      <td>First PM from South India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - 2019</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>30 May 2019- Incumbent</td>\n",
       "      <td>First non-congress PM with two consecutive ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Prime Minister Name     Born-Dead  \\\n",
       "0             Jawahar Lal Nehru   (1889–1964)   \n",
       "1     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2           Lal Bahadur Shastri   (1904–1966)   \n",
       "3   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4                 Indira Gandhi   (1917–1984)   \n",
       "5                 Morarji Desai   (1896–1995)   \n",
       "6                  Charan Singh   (1902–1987)   \n",
       "7                 Indira Gandhi   (1917–1984)   \n",
       "8                  Rajiv Gandhi   (1944–1991)   \n",
       "9                   V. P. Singh   (1931–2008)   \n",
       "10              Chandra Shekhar   (1927–2007)   \n",
       "11          P. V. Narasimha Rao   (1921–2004)   \n",
       "12         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "13             H. D. Deve Gowda   (born 1933)   \n",
       "14           Inder Kumar Gujral   (1919–2012)   \n",
       "15         Atal Bihari Vajpayee   (1924-2018)   \n",
       "16               Manmohan Singh   (born 1932)   \n",
       "17                Narendra Modi   (born 1950)   \n",
       "18                Narendra Modi   (born 1950)   \n",
       "\n",
       "                         Term of Office  \\\n",
       "0         15 August 1947 to 27 May 1964   \n",
       "1           27 May 1964 to 9 June 1964,   \n",
       "2        9 June 1964 to 11 January 1966   \n",
       "3    11 January 1966 to 24 January 1966   \n",
       "4      24 January 1966 to 24 March 1977   \n",
       "5       24 March 1977 to  28 July 1979    \n",
       "6       28 July 1979 to 14 January 1980   \n",
       "7    14 January 1980 to 31 October 1984   \n",
       "8    31 October 1984 to 2 December 1989   \n",
       "9   2 December 1989 to 10 November 1990   \n",
       "10     10 November 1990 to 21 June 1991   \n",
       "11          21 June 1991 to 16 May 1996   \n",
       "12           16 May 1996 to 1 June 1996   \n",
       "13         1 June 1996 to 21 April 1997   \n",
       "14      21 April 1997 to 19 March 1998    \n",
       "15        19 March 1998 to 22 May 2004    \n",
       "16        22 May 2004 to 26 May 2014      \n",
       "17                   26 May 2014 - 2019   \n",
       "18               30 May 2019- Incumbent   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from South India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15   The first non-congress PM who completed a ful...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  \n",
       "18  First non-congress PM with two consecutive ten...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q9: Write a python program to display list of respected former Prime Ministers of India\n",
    "(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "'''\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver =webdriver.Chrome()   # Initialising webdriver\n",
    "driver.get('https://www.jagranjosh.com/')  # Opening website\n",
    "driver.maximize_window()\n",
    "\n",
    "# Click on GK\n",
    "gk_click =driver.find_element(By.XPATH, '/html/body/div[1]/header/nav/div/div/div[3]/ul/li[3]/a')\n",
    "gk_click.click()\n",
    "time.sleep(10)\n",
    "\n",
    "# Click on explore button\n",
    "explore_click =driver.find_element(By.XPATH, '/html/body/div[1]/div[8]/section[5]/div[1]/span/a')\n",
    "explore_click.click()\n",
    "time.sleep(10)\n",
    "\n",
    "# Click on list of prime ministers\n",
    "pm_click =driver.find_element(By.XPATH, '/html/body/div[1]/main/div[1]/div[1]/section[2]/div/ul/li[11]/article/h3/a')\n",
    "pm_click.click()\n",
    "\n",
    "# Creating empty list\n",
    "pm_name =[]\n",
    "born_dead =[]\n",
    "term_of_office =[]\n",
    "remarks =[]\n",
    "\n",
    "# Scraping Prime Minister name\n",
    "pm_tag =driver.find_elements(By.XPATH, '//div[@class=\"TableData\"]/table/tbody/tr/td[2]/div')\n",
    "\n",
    "for i in pm_tag:\n",
    "    pm_name.append(i.text)\n",
    "    \n",
    "# Scraping Prime Minister born-dead information\n",
    "born_tag =driver.find_elements(By.XPATH, '//div[@class=\"TableData\"]/table/tbody/tr/td[3]/div')\n",
    "\n",
    "for i in born_tag:\n",
    "    born_dead.append(i.text)\n",
    "    \n",
    "# Scraping Prime Minister term\n",
    "term_tag =driver.find_elements(By.XPATH, '//div[@class=\"TableData\"]/table/tbody/tr/td[4]/div[1]')\n",
    "\n",
    "for i in term_tag:\n",
    "    term_of_office.append(i.text)\n",
    "    \n",
    "# Scraping Remarks\n",
    "remarks_tag =driver.find_elements(By.XPATH, '//div[@class=\"TableData\"]/table/tbody/tr/td[5]/div')\n",
    "\n",
    "for i in remarks_tag:\n",
    "    remarks.append(i.text)\n",
    "    \n",
    "# Creating DataFrame\n",
    "df =pd.DataFrame({'Prime Minister Name': pm_name, 'Born-Dead': born_dead, 'Term of Office': term_of_office, 'Remarks': remarks})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81c1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q10: Write a python program to display list of 50 Most expensive cars in the world \n",
    "(i.e. Car name and Price) from https://www.motor1.com/\n",
    "'''\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver =webdriver.Chrome()   # Initialising webdriver\n",
    "driver.get('https://www.motor1.com/')  # Opening website\n",
    "\n",
    "search_box =driver.find_element(By.CLASS_NAME, 'm1-search-panel-input m1-search-form-text')\n",
    "search_box.send_keys('50 most expensive cars')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
